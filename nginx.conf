
# you must set worker processes based on your CPU cores, nginx does not benefit from setting more than that
worker_processes auto; #some last versions calculate it automatically


# number of file descriptors used for nginx
# the limit for the maximum FDs on the server is usually set by the OS.
# if you don't set FD's then OS settings will be used which is by default 2000
worker_rlimit_nofile 100000;

#error_log  logs/error.log;
#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

# only log critical errors
error_log logs/error.log crit;

#pid        logs/nginx.pid;


events {
	accept_mutex on;   #设置网路连接序列化，防止惊群现象发生，默认为on
    multi_accept on;  #设置一个进程是否同时接受多个网络连接，默认为off
    # determines how much clients will be served per worker
    # max clients = worker_connections * worker_processes
    # max clients is also limited by the number of socket connections available on the system (~64k)
    worker_connections 4000;

    # optimized to serve many clients with each thread, essential for linux -- for testing environment
    # use epoll;

}


http {
    include       mime.types;
    default_type  application/octet-stream;
	
	log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';


    # cache informations about FDs, frequently accessed files
    # can boost performance, but you need to test those values
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # to boost I/O on HDD we can disable access logs
    access_log off;

    # copies data between one FD and other from within the kernel
    # faster than read() + write()
    sendfile on;

    # send headers in one piece, it is better than sending them one by one
    tcp_nopush on;

    # don't buffer data sent, good for small data bursts in real time
    tcp_nodelay on;

    # reduce the data that needs to be sent over network -- for testing environment
    gzip on;
    gzip_static on;
    gzip_min_length 10240;
    gzip_comp_level 1;
    gzip_vary on;
    gzip_disable msie6;
    gzip_proxied expired no-cache no-store private auth;
    gzip_types
        # text/html is always compressed by HttpGzipModule
        text/css
        text/javascript
        text/xml
        text/plain
        text/x-component
        application/javascript
        application/x-javascript
        application/json
        application/xml
        application/rss+xml
        application/atom+xml
        font/truetype
        font/opentype
        application/vnd.ms-fontobject
        image/svg+xml;

    # allow the server to close connection on non responding client, this will free up memory
    reset_timedout_connection on;

    # request timed out -- default 60
    client_body_timeout 10;

    # if client stop responding, free up memory -- default 60
    send_timeout 2;

    # server will close connection after this time -- default 75
    keepalive_timeout 30;

    # number of requests client can make over keep-alive -- for testing environment
    keepalive_requests 100000;
	
	
	  #########################################
	  # Just For Security Reason
	  #########################################

	  # Security reasons, turn off nginx versions
	  server_tokens off;

	  #more_clear_headers Server; # Custom module: headers-more-nginx-module (https://github.com/openresty/headers-more-nginx-module)

	  # #########################################
	  # # NGINX Simple DDoS Defense
	  # #########################################

	  # limit the number of connections per single IP
	  # limit_conn_zone $binary_remote_addr zone=conn_limit_per_ip:10m;

	  # limit the number of requests for a given session
	  # limit_req_zone $binary_remote_addr zone=req_limit_per_ip:10m rate=5r/s;

	  # zone which we want to limit by upper values, we want limit whole server
	  #server {
	  #	  limit_conn conn_limit_per_ip 10;
	  #	  limit_req zone=req_limit_per_ip burst=10 nodelay;
	  #}

	  # if the request body size is more than the buffer size, then the entire (or partial)
	  # request body is written into a temporary file
	  client_body_buffer_size  128k;

	  # headerbuffer size for the request header from client -- for testing environment
	  client_header_buffer_size 3m;

	  # maximum number and size of buffers for large headers to read from client request
	  large_client_header_buffers 4 256k;

	  # read timeout for the request body from client -- for testing environment
	  # client_body_timeout   3m;

	  # how long to wait for the client to send a request header -- for testing environment
	  client_header_timeout 3m;

	  include /etc/nginx/conf.d/*.conf;

    server {
        listen       80;
        server_name  127.0.0.1;

        charset utf-8;

        #access_log  logs/host.access.log  main;

		return      301 https://$server_name$request_uri;      #这是nginx最新支持的写法
		
        location / {
            root   html;
            index  index.html index.htm;
        }

        #error_page  404              /404.html;

        # redirect server error pages to the static page /50x.html
        #
        error_page   500 502 503 504  /50x.html;
        location = /50x.html {
            root   html;
        }
        
    }


    # another virtual host using mix of IP-, name-, and port-based configuration
    #
    # server {
    #    listen       8000;
    #    listen       somename:8080;
    #    server_name  somename  alias  another.alias;

    #    location / {
    #        root   html;
    #        index  index.html index.htm;
    #    }
    # }
	
	server {
        listen       8001;
        server_name  127.0.0.1;

        location / {
			add_header Access-Control-Allow-Origin *;
			add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';
			add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

			if ($request_method = 'OPTIONS') {
				return 204;
			}
            #root   html;
			root E:/project/microTest/vue/dist;
            index  index.html index.htm;
        }
    }
	
	server {
        listen       8002;
        server_name  127.0.0.1;
		
        location / {
			add_header Access-Control-Allow-Origin *;
			add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';
			add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

			if ($request_method = 'OPTIONS') {
				return 204;
			}
            #root   html;
			root E:/project/microTest/react16/build;
            index  index.html index.htm;
        }
    }
	
	
	server {
        listen       8003;
        server_name  127.0.0.1;
		
        location / {
			add_header Access-Control-Allow-Origin *;
			add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';
			add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

			if ($request_method = 'OPTIONS') {
				return 204;
			}
            #root   html;
			#root D:/WebTest/antdreact/build;
			#root D:/WebTest/antdumi/dist;
			root E:/project/materialFront/Build;
            index  index.html index.htm;
        }
    }
	
	# server {
		
    #     listen       8004;
    #     server_name  127.0.0.1;
		
    #     location / {
	# 		add_header Access-Control-Allow-Origin *;
	# 		add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS';
	# 		add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization';

	# 		if ($request_method = 'OPTIONS') {
	# 			return 204;
	# 		}
    #         #root   html;
	# 		#root D:/WebTest/antdreact/build;
	# 		root E:/project/antdwebpack5test/build;
    #         index  index.html index.htm;
    #     }
    # }


    # HTTPS server
    #
    # server {
	# 		#比起默认的80 使用了443 默认 是ssl方式  多出default之后的ssl
	# 	#开启  如果把ssl on；这行去掉，ssl写在443端口后面。这样http和https的链接都可以用
       
    #  	listen 443 ssl http2;
    #     server_name  127.0.0.1;
		
	# 	#证书(公钥.发送到客户端的)
    #     ssl_certificate      ./ssl/server.crt;
	# 	#私钥,
    #     ssl_certificate_key  ./ssl/server.key;

    #     ssl_stapling_verify on;
    #     ssl_session_timeout 1d;
    #     ssl_session_tickets off;
    #     ssl_session_cache shared:SSL:10m;
		
		
	# 	ssl_client_certificate          ./ssl/selfCA.crt;
    #     ssl_verify_client               on;
		
	# 	#ssl_stapling on;
	# 	ssl_protocols TLSv1.1 TLSv1.2 TLSv1.3;
	# 	#ssl_ciphers "ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:AES128-GCM-SHA256:AES256-GCM-SHA384:AES128-SHA256:AES256-SHA256:AES128-SHA:AES256-SHA:AES:CAMELLIA:DES-CBC3-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!MD5:!PSK:!aECDH:!EDH-DSS-DES-CBC3-SHA:!EDH-RSA-DES-CBC3-SHA:!KRB5-DES-CBC3-SHA";
	# 	#ssl_ciphers  TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256;
	# 	ssl_ciphers EECDH+AES:EECDH+CHACHA20:!SHA;
		
	# 	ssl_prefer_server_ciphers on;
	# 	add_header Strict-Transport-Security "max-age=63072000; includeSubdomains; preload";
		
	# 	#location ~ ^/.+\.json {
	# 	#	default_type application/json;
	# 	#}

	# 	if ($request_method = 'OPTIONS') {
	# 		return 204;
	# 	}
    #     location / {
			
	# 		#root D:/WebTest/materialfront/build/;
	# 		root E:/webTest/antdFront/build;
    #         index index.html;
	# 		try_files $uri /index.html;
 
    #     }
		
	# 	# 静态文件缓存，启用Cache-Control: max-age、Expires
	# 	#location ~ ^/static/(css|js|media)/ {
	# 	#  expires 10y;
	# 	#  access_log off;
	# 	#  add_header Cache-Control "public";
	# 	#}
    # }

}
